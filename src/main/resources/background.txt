General Instructions
In this learning session, the goal is to write a vision essay that describes the future of education. Please describe, in 200 to 400 words, how you envision learning in a school in 2035.
Please consult the materials in this learning environment that provide information about three important topics for envisioning the future of education in 2035.
1. Artificial intelligence and its application
2. What differentiation is and how it is applied in the classroom context
3. The process of scaffolding and how it optimizes students learning
The goal of the learning session is to integrate these topics into a vision essay that describes learning in a school in 2035.
At the end of the learning session, you should be able to:
explain the concepts of artificial intelligence, scaffolding and differentiation
explain how they affect learning
apply them in the context of education
combine the concepts into a future vision for education
For more information about the criteria of the essay, you are required to read the rubric (important!!).
You will read the materials, study the concepts and write the essay in 120 minutes. Please note that this is a challenging task and you should work efficiently. We advise you to focus on the three important concepts, their relationships and how their combination can form a future vision for education when reading the materials and writing the essay.







Rubric

This is the rubric. The rubric is used to score the essay, and the full score is 30 points.
There are four global criteria:
Word count: The essay consists of 200 to 400 words; Yes (2 points), No (0 points)
Basic writing skills: The essay is clearly a mature draft, has no low-level writing mistakes, such as missing texts, ‘placeholders’, messy typography, many spelling and grammatical errors; Yes (2 points), Partial (1 point) No (0 point)
Academic writing skills: The writing of this essay should conform to the norms of academic writing, such as using appropriate logic structure, good flow and linkers usage, correct verbs and tenses and voices, consistent with academic writing style; Yes (4 points), Partial (1-3 point) No (0 point)
Originality: Your writing should be your own opinion elaborated in your own words, not simply copy-pasted sentences from the material; Yes (2 points), Partial (1 point) No (0 point)
In addition, the content will be evaluated according to the following criteria:
The role of AI in education: Reflects the information provided in the text and the student is able to apply in to learning and uses it to create an innovative vision of education in 2035
Scaffolding to optimize learning: Reflects the information provided in the text and the student is able to apply in to learning and uses it to create an innovative vision of education in 2035
Differentiation practices in the classroom: Reflects the information provided in the text and the student is able to apply in to learning and uses it to create an innovative vision of education in 2035
Integration of three topics: The integration reflects the information provided in the text and the student is able to apply it to learning uses it to create an innovative vision of education in 2035
Future vision on education: The vision on future education makes sense and goes beyond what is in the text and appropriate innovative ideas are discussed
1: Artificial Intelligence in Education
1.1 Definition of Artificial Intelligence
Artificial intelligence is the ability of computers to perform tasks that require humans to use their intelligence, like: observing, recognizing, interacting with the environment, analyzing, reasoning, solving problems and making predictions. For example, you can find AI in voice assistants on smartphones, self-driving cars or in robots that compile orders in large warehouses. But it can also be found in programs that, without any human intervention, can write factual accounts about annual figures or produce diagnoses of medical disorders. A huge range of different manifestations, but they all use AI as their foundation.

Artificial intelligence does not have to mimic the functioning of the brain in order to be effective, in the same way that an aeroplane can fly without having to move its wings like a bird. Due to the rapid development of chip technology, AI can store, process and analyze many times more data than a human brain. However, not all human capabilities can be approximated with brute computational power at this time.

An AI system that can mimic a complete human being, otherwise known as artificial general intelligence, still has a long way to go. Task-specific artificial intelligence, on the other hand, is already all around us. You can find it in a wide variety of products (see Figure 1). However, AI technology of this kind must be made suitable for a specific market or field of activity. For example, there are great expectations for AI in education, but for the time being, we see it only to a limited extent in tangible educational products.
1.2 History of Artificial Intelligence
The first work that is now generally recognized as AI was done by Warren McCulloch and Walter Pitts. They drew on three sources: knowledge of the basic physiology and function of neurons in the brain; a formal analysis of propositional logic due to Russell and Whitehead; and Turing’s theory of computation. They proposed a model of artificial neurons in which each neuron is characterized as being “on” or “off,” with a switch to “on” occurring in response to stimulation by a sufficient number of neighboring neurons. The state of a neuron was conceived of as “factually equivalent to a proposition which proposed its adequate stimulus.” They showed, for example, that any computable function could be computed by some network of connected neurons, and that all the logical connectives (and, or, not, etc.) could be implemented by simple net structures. McCulloch and Pitts also suggested that suitably defined networks could learn. Donald Hebb (1949) demonstrated a simple updating rule for modifying the connection strengths between neurons. His rule, now called Hebbian learning, remains an influential model to this day.

The Turing Test, proposed by Alan Turing (1950), was designed to provide a satisfactory operational definition of intelligence. A computer passes the test if a human interrogator, after posing some written questions, cannot tell whether the written responses come from a person or from a computer.

The computer would need to possess the following capabilities:
natural language processing to enable it to communicate successfully in English;
knowledge representation to store what it knows or hears;
automated reasoning to use the stored information to answer questions and to draw new conclusions;
machine learning to adapt to new circumstances and to detect and extrapolate patterns.

Turing’s test deliberately avoided direct physical interaction between the interrogator and the computer, because physical simulation of a person is unnecessary for intelligence. However, the so-called total Turing Test includes a video signal so that the interrogator can test the subject’s perceptual abilities, as well as the opportunity for the interrogator to pass physical objects “through the hatch.” To pass the total Turing Test, the computer will need computer vision to perceive objects, and robotics to manipulate objects and move about.

Turing deserves credit for designing a test that remains relevant 60 years later. Yet AI researchers have devoted little effort to passing the Turing Test, believing that it is more important to study the underlying principles of intelligence than to duplicate an exemplar. The quest for “artificial flight” succeeded when the Wright brothers and others stopped imitating birds and started using wind tunnels and learning about aerodynamics. Aeronautical engineering texts do not define the goal of their field as making “machines that fly so exactly like pigeons that they can fool even other pigeons.”
1.3 How does AI work?
Artificial intelligence essentially consists of two components: a self-learning algorithm and data. An algorithm is a series of instructions that leads to a certain result. In computers, this takes the form of a computer program. One example of an algorithm that you encounter and use in everyday life is a recommender system. Based on your viewing behavior, video streaming services make recommendations about other videos that you may find interesting. To be able to make these recommendations, data is needed. In this case, the data is your own viewing behavior and that of others. Data is the raw material that allows AI to work. By analyzing more data, the algorithm can make better recommendations.

An important difference between other programs and those that use AI is the ability to learn. Think of a chess program. You could program it with every possible strategy, decision and rule, prepared in advance. In terms of possibilities, the end product then remains limited to what the programmers have told the program about effective strategies. With an AI chess program, you don’t come up with all the steps in advance, but you make an algorithm that is capable of learning from data. You ‘feed’ it millions of chess games that people have played. The algorithm analyses everything and then extracts strategies, rules and decisions. It would be impossible for people to analyze so much data, but an AI program is able to. After the algorithm has been trained, it can play chess against people in the form of a computer program.

Programs that are trained with AI don’t necessarily learn constantly. It is a snapshot, as it were, of all knowledge and experiences acquired up to that point. Its functioning is as good or bad as the quality of the devised algorithm and the data with which it was trained. The algorithm makes decisions based on what it has learned before you can eventually use it as a program. Of course, the program also collects new data as you use it. To make the AI even better, this data must first be processed and a new snapshot can be made. You can compare this new snapshot with a software update.

Just like people, AI systems sometimes have prejudices, although these often arise unintentionally. The developer can consciously or unconsciously program them in the algorithm. It is also possible that the dataset with which the algorithm is being trained is incomplete, polluted or incorrect. As AI systems start carrying out more and more tasks for us, we must be wary of these biases.
1.4 Ethics and risks of developing AI
If the effects of AI technology are more likely to be negative than positive, then it would be the moral responsibility of workers in the field to redirect their research. Many new technologies have had unintended negative side effects: nuclear fission brought Chernobyl and the threat of global destruction; the internal combustion engine brought air pollution, global warming, and the paving-over of paradise. In a sense, automobiles are robots that have conquered the world by making themselves indispensable.

All scientists and engineers face ethical considerations of how they should act on the job, what projects should or should not be done, and how they should be handled. AI, however, seems to pose some fresh problems beyond that of, say, building bridges that don’t fall down:

People might lose their jobs to automation.
People might have too much (or too little) leisure time.
People might lose their sense of being unique.
AI systems might be used toward undesirable ends.
The use of AI systems might result in a loss of accountability.
The success of AI might mean the end of the human race.

In David Lodge’s Small World (1984), a novel about the academic world of literary criticism, the protagonist causes consternation by asking a panel of eminent but contradictory literary theorists the following question: “What if you were right?” None of the theorists seems to have considered this question before, perhaps because debating unfalsifiable theories is an end in itself. Similar confusion can be evoked by asking AI researchers, “What if you succeed?”

As mentioned before, there are ethical issues to consider. Intelligent computers are more powerful than dumb ones, but will that power be used for good or ill? Those who strive to develop AI have a responsibility to see that the impact of their work is a positive one. The scope of the impact will depend on the degree of success of AI. Even modest successes in AI have already changed the ways in which computer science is taught and software development is practiced. AI has made possible new applications such as speech recognition systems, inventory control systems, surveillance systems, robots, and search engines.

We can expect that medium-level successes in AI would affect all kinds of people in their daily lives. So far, computerized communication networks, such as cell phones and the Internet, have had this kind of pervasive effect on society, but AI has not. AI has been at work behind the scenes—for example, in automatically approving or denying credit card transactions for every purchase made on the Web—but has not been visible to the average consumer.
1.5 Supervised machine learning
There isn’t one specific form of AI. The different forms of AI use different approaches, each with its own strengths and opportunities. AI products and services use one or more forms of AI. Here, we will discuss the four most commonly used forms.

Supervised Machine Learning

With this form of AI (see Figure 2), you know in advance what the correct outcome is and you teach the algorithm the relationships between various data. All of the data used is labelled by people, in much the same way that you would indicate the meaning of each column above the columns of a spreadsheet. The algorithm doesn’t have to figure out what the data means or which data groups belong together. By feeding the algorithm more and more data, the results become more and more accurate. As an example, think of determining the selling price of a house. By giving an algorithm lots of historical data of sold houses with their final selling price, plot size, location and other features, it gets a better understanding of the relationships between the factors. This allows it to more accurately determine a selling price.
1.6 Unsupervised machine learning
With this form of AI (see Figure 3), you don’t program what the right outcome is and exactly which data is relevant, but you ask an algorithm to cluster the data by finding patterns in a dataset. Algorithms like these can be used if you don’t want to or are unable to classify all the data yourself, or because you want to discover new connections and clusters. One practical example is a video service that recommends other videos that are likely to be of interest to you. In this case, you don’t want to think up every single category in advance, but you want the system to determine them, and to keep recognizing and updating them.
1.7 Reinforcement learning
In this form (see Figure 4), the algorithm learns to perform a task by getting rewarded for actions that provide the right outcome. You can use this type of algorithm if there is little data available. It is comparable with training a dog: if the dog does something right, you give it a reward, otherwise, no reward. The algorithm then learns what the desired actions are that contribute to achieving a specific goal. These types of algorithms are also used in self-driving cars so that, learning from the driver, they can make better decisions. Or, in the case of a robot learning to walk, it learns by trial and error how big the right step has to be.
1.8 Deep Learning
You can use this form (see Figure 5) with ‘unstructured data’ such as images, videos or sound recordings. Compared with the other forms, it needs much more data, but it may yield even more accurate results. Deep learning algorithms consist of different layers. Each layer learns new and more complex properties of the data. For example, you can create an AI system that recognizes animals. By providing it with lots of examples of different birds, the system learns to recognize various characteristics. For example, one layer of the algorithm analyses the shape of the object. By recognizing wings and a beak, it knows that this particular object is a bird. Another layer analyses the color of the bird and recognizes that it is a yellow bird. Based on the combination of these characteristics, a subsequent layer could also recognizethe specific type of bird, for example a yellow parakeet. If you show the algorithm a new bird that wasn’t in the training set, it can still recognize the bird on the basis of its characteristics.


2: Differentiation in Education
2.1 What is Differentiation?
Student ability in untracked primary classrooms may vary widely, which poses challenges for teachers. This variability does not only occur in schools with a policy of full inclusion, but in all classrooms that are created based on student age. The quality of schools is largely determined by how teachers deal with these (cognitive) differences between students and by how they adapt their instruction to individual needs. This requires teachers to develop advanced professional skills in addition to their basic skills of classroom management and general didactics. Note that this hierarchy of professional skills stems from practice, not from principle: although taking into account individual student needs is fundamental of good teaching and therefore should be a basic skill, research shows that novice teachers first need to master other skills before they can start attending to differences between students well. These advanced professional skills are summarized in the concept ‘differentiation’.

Differentiation is a combination of careful progress monitoring and adapting instruction in response. It is “an approach to teaching in which teachers proactively modify curricula, teaching methods, resources, learning activities, and student products to address the diverse needs of individual students and small groups of students to maximize the learning opportunity for each student in a classroom”. It is related to the concept of aptitude-treatment interaction, which emphasizes that education is most effective when instruction is closely matched to the student's own capacities and talents, and also acknowledges the complex interplay between characteristics of the student, task and instruction.

Differentiation is an overall approach to teaching and can include combinations of many practices, like flexible (heterogeneous or homogeneous) grouping, detailed progress monitoring, using adaptive computer programs or learning materials, modifying learning content, adapting instruction for weaker students, and providing opportunities for acceleration for stronger students. Differentiation practices can be applied to areas of learning content, learning process, learning product. Tomlinson (2014) extends this list with affect or environment. Furthermore, teachers may not only take into account differences in students' cognitive abilities, but also other differences such as in students' motivation or interest for example. This broad array of differentiation options is appealing, but does pose some challenges in a theoretical sense because of the many practices and understandings that it may entail. The potential relevance of differentiation in which student differences in ability or performance are taken into account is clear from theoretical underpinnings in theories such as Vygotsky's Zone of Proximal Development, which describes how learning could be advanced by providing students tasks that are just outside their current level of mastery.
2.2 Using differentiation to adapt education
How teachers choose to apply differentiation seems to be related to the implicit or explicit learning goals they have for their classroom as a whole. From a theoretical point of view, teachers can strive for convergence or divergence. Teachers aiming at convergence mainly focus on helping all their students to reach a basic performance level. This implies that they may dedicate additional time and effort to low-achieving students in order to help them reach a minimum performance level, even when this is at the expense of time they had reserved for high-ability students. Teachers aiming at divergence, on the contrary, mainly focus on helping all students to reach their highest potential, dividing attention equally between students with lower, average, and higher ability. Their use of ability-appropriate performance goals for (groups of) students at different ability levels may lead to a widening of the gap between lower- and higher-ability students. Convergent and divergent goals thus lead to different pedagogical-didactical decisions. In practice, though, most teachers are likely to combine convergent and divergent goals, and will aim to reach a minimum performance level with low-ability students while also offering high-ability students the opportunity to extend their knowledge without proceeding (too much) ahead of their classmates.

Differentiation in education is a highly debated topic, especially when it is applied in the form of homogeneous grouping. Teachers appear less accurate in estimating students’ cognitive abilities when they are placed in homogeneous classrooms. Most concerns regarding homogeneous grouping are related to the reduced learning opportunities for low-ability students: within these groups, students cannot profit from the input of higher-ability peers or from the role models that high-ability students can be. Furthermore, teachers may have lower expectations of low-ability students and, therefore, unconsciously limit their opportunity to learn. This is especially relevant for students from impoverished backgrounds or minority groups, who might be labeled as being of “low ability” even before they have had the opportunity to show their potential. Teacher expectations and beliefs are found to correlate with the socioeconomic status (SES) of students. When students from low SES families are placed in a low-ability group too soon – based on general estimates or prejudices, rather than on actual performance level – they might encounter lower expectations and, as a result, less demanding teaching and unequal learning opportunities. The debate on how to implement differentiation in such a way that students of all ability levels profit from it should be informed by empirical research data. Review studies of the effects of differentiation practices are, therefore, important.
2.3 Standards for teaching
In the midst of the debates about how to improve teaching quality, an emerging strategy across a number of nations has been the articulation of standards for what teachers should learn and be able to do. The theory of action is that such standards – used to guide licensing or certification of candidates and/or accreditation of programmes – can guide teacher learning and influence entry, continuation or recognition in the field.

The United States has been a leader in this regard, with the creation of the National Board for Professional Teaching Standards in 1987, which not only articulated standards and developed assessments for evaluating accomplished teaching, but also led to revisions of standards for beginning teacher licensing and preparation through the Interstate New Teacher Assessment and Support Consortium (INTASC). Research has found that veteran teachers who meet the National Board’s standards are more effective than those who do not and that the process of becoming Board-certified helps teachers improve their practice.

In recent years, the creation of a performance assessment for evaluating new teachers has also taken hold, with more than one thousand educators across the country having collaborated to create a national version of an assessment that can inform initial licensure and provide leverage on improving teacher preparation. Educator preparation programmes in more than 30 states have piloted this teacher performance assessment. A similar assessment in California has been found to measure teachers’ later effectiveness and to produce improvements in teacher education in that state. If such high-quality performance assessments can be tapped, they could create an entry standard that puts to rest the futile arguments about the quality of various traditional and alternative routes and set a meaningful benchmark for all programmes and candidates to meet.

The critical question for the teacher standards movement, where it is emerging, is how the standards will be used, how universally they will be applied and how they may leverage stronger learning opportunities and a more common set of knowledge, skills and commitments across the profession. Robust standards weakly applied can be expected to have much less effect than those that are used, as in other professions, as an effectively endorsed expectation for candidates and institutions to meet.


3: Scaffolding in Education
3.1 The development of scaffolding
Drawing on the metaphor of scaffolding in building construction, Wood, Bruner, and Ross (1976) proposed the concept of scaffolding to describe how children, with the help of someone more knowledgeable to share and support their problem solving, can perform more complex tasks than they would otherwise be capable of performing on their own.
The concept of scaffolding and its use in the learning sciences draws on multiple research traditions. The idea arises from Vygotskian-based study of adult-child and peer interactions, primarily in the context of language development. It draws on Vygotsky’s notion of development and learning as occurring in a zone of proximal development (ZPD). The ZPD (Figure 6) refers to a range of tasks that are outside of the learners’ current independent ability but are achievable with appropriate help, thereby extending their range of independent activity. By actively participating in working through these more complex tasks, children learn from the experience and go beyond what they can accomplish alone. Another influence is the study of classical apprenticeship in which learning occurs as people with varying degrees of expertise engage in context in authentic tasks.
3.2 What is cognitive apprenticeship?
First, the term apprenticeship emphasizes that cognitive apprenticeship was aimed primarily at teaching the processes that experts use to handle complex tasks. Like traditional apprenticeship, cognitive apprenticeship emphasizes that knowledge must be used in solving real-world problems. Conceptual knowledge is learned in a variety of contexts, encouraging both a deeper understanding of the meaning of the concepts themselves, and a rich web of memorable associations between them and the problem-solving contexts. This dual focus on expert processes and learning in context are shared by both traditional apprenticeship and cognitive apprenticeship.

Second, the term cognitive emphasizes that the focus is on cognitive skills, rather than physical ones. Traditional apprenticeship evolved to teach domains in which the target skills are externally visible, and thus readily available to both student and teacher for observation, refinement, and correction, and bear a transparent relationship to concrete products. But given the way that most subjects are taught in school, teachers cannot make fine adjustments in students’ application of skill and knowledge to tasks, because they can’t see the cognitive processes in students’ heads. By the same token, students do not usually have access to the problem-solving processes of instructors as a basis for learning through observation. Before apprenticeship methods can be applied to learn cognitive skills, the learning environment has to be changed to make these thought processes visible. Cognitive apprenticeship is designed to bring these cognitive processes into the open, where students can observe and practice them.

Reflection encourages learners to look back on their performance in a situation and compare their performance to other performances, such as their own previous performances and those of experts. Reflection has received much attention as a vital aspect of the learning process for both children and adults. Schon (1983) describes how systematic reflection on practice is critical for many professionals engaged in complex activities. Designers of learning environments often build supports for reflection into tasks by asking students to discuss and reflect on the strategies used to guide their actions. Reflection can highlight the critical aspects of a performance and encourage learners to think about what makes for a good performance and how they might improve in the future.

There are two forms that reflection can take, both of which are enhanced by technology: 1) comparison of your performance to that of others, and 2) comparison of your performance to a set of criteria for evaluating performances.
3.3 What is scaffolding
A central idea in scaffolding is that the work is shared between the learner and some more knowledgeable other or agent. Scaffolding enables not only the performance of a task more complex than the learner could handle alone, but also enables learning from that experience. The collaboration with a “more knowledgeable other” (typically called a tutor in early work on scaffolding) can help learners bridge from their current knowledge to more sophisticated practices. Several aspects of knowledge and skills may need to be bridged. Learners may have an incomplete definition of the problem, not able to fully determine the goal of the task, the expected products, or the resources involved. Their relevant skill set may be incomplete. Regulating the problem solving process,determining which actions to take, and when and how, often pose serious challenges for learners. Thus, what learners need to acquire through the scaffolded activity is an inventory of relevant actions and proficiency in the orchestration of these actions.

The more knowledgeable other providing scaffolding proceeds as though the learner already does possess this knowledge and skill. Thus, learners may encounter directives that they do not understand and are pushed to construct an understanding of the directive and to associate it with their emerging definition of the task. This understanding is built by having the tutor perform the required action for the learner (modeling) or animate the actions of the learners by helping to implement their actions, such as in manipulating their hands in a loom or rephrasing their words to better align with the task. This process is also true for nonverbal actions and directives. Over repeated interactions, the learner imitates the modeled actions and associates them with the directive and the definition of the task. This is one of the mechanisms that explains how learning occurs through scaffolding, and is referred to as prolepsis.

Similarly, the joint activity of scaffolding tends to begin with other- regulated behavior, in which the tutor directs, hints, or offers prompts that help regulate the sequence of relevant actions. Over time, learners appropriate this guidance and begin to regulate their own actions as the tutor gradually reduces guidance, resulting in fading of scaffolding. Eventually, the learners regulate their activity without overt speech, as the “other speech” becomes internalized and eternal guidance is no longer needed.
3.4 Applications of scaffolding
Scaffolding is fundamentally different from instructional approaches based on the decomposition of complex skills and tasks into minimal constituent components. The instructional design approach of breaking skills and tasks into component parts has its roots in behaviorist approaches to learning and education. Based on behaviorist theory, learners acquire more complex behaviors from simpler learned behaviors, for example, adding a new step to a known sequence. Analyzing tasks into constituent components, teaching these first, and then building up to more complex behaviors has become a common approach in traditional instructional design. In these approaches, learning requires small-scale tasks created specifically for developing a particular subskill. Such tasks may not reflect actual tasks outside the learning environment.

In contrast, scaffolding is an element of contextualized approaches that situate the learning of new skills in more complex tasks such as apprenticeship and project-based learning. In these contextualized approaches, learners work on real-world or expert complex tasks, which motivate developing subskills and requisite knowledge, in context, as needed, applying the knowledge and skills as they are constructed. Embedding guidance in context as learners perform a full contextualized expert-like task is the essence of the pedagogical logic of scaffolding.

Because scaffolding is a contextualized holistic approach, it facilitates transfer, and it cultivates an understanding of the objectives of a discipline and of the relationship between objectives and procedures. Understanding the ultimate aim and application context of component skills is often absent from instruction that is organized around the decomposition of requisite skills. In traditional instruction, learners see the particular skill, such as solving linear equations or learning the formula for photosynthesis, as an aim in and of itself, and they do not learn the potential relevance and applicability of this knowledge. This results in inert knowledge, in which learners cannot apply what they learn. In contrast, when learners work on component skills in the context of the full target application task, they learn how the component skills should work in and when and how they should be applied, which facilitates their independent and appropriate use in the future.
3.5 Applications of cognitive apprenticeship
Coaching consists of observing students while they carry out tasks and offering hints, challenges, scaffolding, feedback, modeling, reminders, and new tasks aimed at bringing their performance closer to expert performance. Coaching relates to specific problems that arise as the student attempts to accomplish a task. In Palincsar and Brown’s (1984) reciprocal teaching of reading, the teacher coaches students while they formulate questions on the text, clarify their difficulties, generate summaries, and make predictions about what will come next.

Modeling involves an expert performing a task so that the students can observe and build a conceptual model of the processes that are required to accomplish it. In cognitive domains, this requires the externalization of usually internal processes and activities. For example, a teacher might model the reading process by reading aloud in one voice, while verbalizing her thought processes in another voice. In mathematics, Schoenfeld (1985) models the process of solving problems by thinking aloud while trying to solve novel problems students bring to class. Recent research suggests that delaying expert modeling of a task until students have tried to generate their own ideas and strategies for performing the task is particularly effective.

Increasing complexity refers to sequencing of tasks, such that more of the skills and concepts necessary for expert performance are required. For example, in reading, increasing task complexity might consist of progressing from relatively short texts – with simple syntax and concrete description – to texts in which complexly interrelated ideas and the use of abstractions make interpretation difficult.

Increasing diversity refers to sequencing of tasks so that a wider variety of strategies or skills is required. As a skill becomes well learned, it becomes increasingly important that tasks requiring a diversity of skills and strategies be introduced, so that the student learns to distinguish the conditions under which they apply. Moreover, as students learn to apply skills to more diverse problems, their strategies acquire a richer net of contextual associations and thus are more readily available for use with unfamiliar or novel problems. For mathematics, task diversity might be attained by intermixing very different types of problems, such as asking students to solve problems that require them to use a combination of algebraic and geometric techniques.

